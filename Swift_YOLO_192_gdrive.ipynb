{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcory-hub/swift-yolo/blob/main/Swift_YOLO_192_gdrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Swift-YOLO model 192x192 px\n"
      ],
      "metadata": {
        "id": "jmFr-Sd-MFNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This colab notebook is based on the colab notebooks on [ssmca-model-zoo](https://github.com/Seeed-Studio/sscma-model-zoo)"
      ],
      "metadata": {
        "id": "h8H8o_XCQK8h"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEegpjhP2xWJ"
      },
      "source": [
        "**Category:** Object Detection\n",
        "\n",
        "**Algorithm:** [Swift-YOLO](configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py)\n",
        "\n",
        "**Dataset:** Custom dataset from Google Drive (requires Gmail account)\n",
        "\n",
        "---\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "Follow these steps before running the notebook:\n",
        "\n",
        "### Step 1: Enable GPU Acceleration\n",
        "\n",
        "1. Click `Runtime` ‚Üí `Change runtime type`\n",
        "2. Select `GPU` in `Hardware accelerator`\n",
        "3. Click `Save`\n",
        "\n",
        "**Expected environment** (verify in first code cell output):\n",
        "- GPU: T4 or higher\n",
        "- Python 3.11.13\n",
        "\n",
        "---\n",
        "\n",
        "### Step 2: Copy dataset in COCO format\n",
        "\n",
        "1. Make sure images and labels from your dataset have this folder structure with these exact names. (Augmen\n",
        "\n",
        "```\n",
        "üóÇÔ∏è dataset\n",
        "  üóÇÔ∏è train\n",
        "  _annotations.coco.json\n",
        "  image1.jpg\n",
        "  image2.jpg\n",
        "  ...\n",
        "  üóÇÔ∏è valid\n",
        "  _annotations.coco.json\n",
        "  image3.jpg\n",
        "  image4.jpg\n",
        "  ...\n",
        "```\n",
        "\n",
        "2. Zip the dataset folder to a file names `dataset.zip`. On mac use `zip -r dataset.zip dataset -i '*.jpg' '*.txt' '*.yaml'` to exclude metadatafiles\n",
        "\n",
        "3. Make in /content/drive/MyDrive the folder `yolo`. Copy the `dataset.zip` file to this folder, it is needed to make a callibration image set and your yolo model, fe `best.pt` to this folder. For the model you can use a custom name and adjust it in the options below.\n",
        "\n",
        "4. Copy the `dataset.zip` file to the folder /content/drive/MyDrive/yolo.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Step 4: Adjust Number of Classes\n",
        "\n",
        "‚ö†Ô∏è **IMPORTANT: Update class count if your dataset has a different number of classes**\n",
        "\n",
        "- **Default**: 4 classes\n",
        "- **Action**: Search for all occurrences of `num_classes` or class count settings in the notebook and update them to match your dataset\n",
        "\n",
        "**Example**: If your dataset has 5 classes, change `num_classes=4` to `num_classes=5` in all relevant code blocks.\n",
        "\n",
        "---\n",
        "\n",
        "## Ready to Run\n",
        "\n",
        "After completing all setup steps above, you can run the notebook cells in order. The notebook will:\n",
        "1. Download your dataset from google drive\n",
        "2. Train the Swift-YOLO model\n",
        "3. Export the model as `int8_vela.tflite` for Grove Vision AI V2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check PGU and Python version"
      ],
      "metadata": {
        "id": "jSvMrw5uQfli"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "V6Hespbd2xWL"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "!nvidia-smi\n",
        "\n",
        "# Check Python version\n",
        "!python --version"
      ],
      "metadata": {
        "id": "gKht7yXrNzKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlf8_bNg2xWK"
      },
      "source": [
        "## Prerequisites\n",
        "### Setup SSCMA\n",
        "Clone the [repository](https://github.com/Seeed-Studio/ModelAssistant) and install the dependencies.\n",
        "\n",
        "(you can ignore the ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v97_kWgU2xWK"
      },
      "outputs": [],
      "source": [
        "!pip install ethos-u-vela\n",
        "!git clone https://github.com/Seeed-Studio/ModelAssistant.git -b 2.0.0  #clone the repo\n",
        "%cd ModelAssistant\n",
        "!. ./scripts/setup_colab.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mKfjj3T2xWL"
      },
      "source": [
        "### Download the pretrain model weights file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SewV9Zvp2xWL"
      },
      "outputs": [],
      "source": [
        "%mkdir -p Swift-YOLO_192\n",
        "!wget -c https://files.seeedstudio.com/sscma/model_zoo/detection/animal/animal_detection.pth -O Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT5ctFj-2xWL"
      },
      "source": [
        "### Download the dataset\n",
        "and put it in the correct directory (ModelAssistant/Swift-YOLO_192)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy zipped dataset to colab and unzip the dataset\n",
        "!scp '/content/drive/MyDrive/dataset.zip' '/content/dataset.zip'\n",
        "!unzip '/content/dataset.zip' -d '/content/ModelAssistant/Swift-YOLO_192/'"
      ],
      "metadata": {
        "id": "Vuhw1EfJFaHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional use a custom swift-yolo model"
      ],
      "metadata": {
        "id": "XMXpPH2j1YEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '/content/drive/MyDrive/best_coco_bbox_mAP_epoch_100.pth' 'Swift-YOLO_192/pretrain.pth'"
      ],
      "metadata": {
        "id": "zJUqD0EzIKgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5XfzBgq2xWL"
      },
      "source": [
        "## Train a model with SSCMA\n",
        "All the training parameters are in the `config.py` file, you can change the parameters to train your own model.\n",
        "\n",
        "\n",
        "- `data_root` - the datasets path.\n",
        "- `epochs`- the train epochs. **we use 10 epochs as an example**.\n",
        "- `batch` - the batch size.\n",
        "- `height` - the image height.\n",
        "- `width` - the image width.\n",
        "- `load_from` - the pretrained model path.\n",
        "- `num_classes` - the number of classes.\n",
        "\n",
        "You can overwrite the parameters in the `config.py` file by using the `--cfg-options` argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qPELuZQ2xWL"
      },
      "outputs": [],
      "source": [
        "!sscma.train configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Swift-YOLO_192 \\\n",
        "    num_classes=4 \\\n",
        "    epochs=3  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    batch=256 \\\n",
        "    lr=0.16 \\\n",
        "    data_root=Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zip and download the Swift-YOLO_192 model"
      ],
      "metadata": {
        "id": "L-umWJwvW_bX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "\n",
        "# Define the paths\n",
        "folder_path = '/content/ModelAssistant/Swift-YOLO_192'\n",
        "zip_filename = 'Swift-YOLO_Models.zip'\n",
        "\n",
        "# Create the zip file\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    # List all items in the directory\n",
        "    for item in os.listdir(folder_path):\n",
        "        item_path = os.path.join(folder_path, item)\n",
        "\n",
        "        # Only add to zip if it's a file (skips all subdirectories)\n",
        "        if os.path.isfile(item_path):\n",
        "            zipf.write(item_path, arcname=item)\n",
        "            print(f\"Added to zip: {item}\")\n",
        "\n",
        "# Automatically trigger the download to your computer\n",
        "files.download(zip_filename)"
      ],
      "metadata": {
        "id": "v4SvKLwcWw0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy model on [SenseCraft AI platform](https://sensecraft.seeed.cc/ai/model)\n",
        "\n",
        "1. Click `My Own Models`\n",
        "2. Select `+ Add Model`\n",
        "3. Follow the instructions\n",
        "4. Download the int8_vela.tflite model"
      ],
      "metadata": {
        "id": "QjNdDA3Cb6iz"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}