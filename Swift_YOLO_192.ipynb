{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcory-hub/swift-yolo/blob/main/Swift_YOLO_192.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Swift-YOLO model 192x192 px\n"
      ],
      "metadata": {
        "id": "jmFr-Sd-MFNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This colab notebook is based on the colab notebooks on [ssmca-model-zoo](https://github.com/Seeed-Studio/sscma-model-zoo)"
      ],
      "metadata": {
        "id": "h8H8o_XCQK8h"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEegpjhP2xWJ"
      },
      "source": [
        "**Category:** Object Detection\n",
        "\n",
        "**Algorithm:** [Swift-YOLO](configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py)\n",
        "\n",
        "**Dataset:** Custom dataset from Roboflow (requires Roboflow account and API key)\n",
        "\n",
        "---\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "Follow these steps before running the notebook:\n",
        "\n",
        "### Step 1: Enable GPU Acceleration\n",
        "\n",
        "1. Click `Runtime` ‚Üí `Change runtime type`\n",
        "2. Select `GPU` in `Hardware accelerator`\n",
        "3. Click `Save`\n",
        "\n",
        "**Expected environment** (verify in first code cell output):\n",
        "- GPU: T4 or higher\n",
        "- Python 3.11.13\n",
        "\n",
        "---\n",
        "\n",
        "### Step 2: Configure Roboflow API Key\n",
        "\n",
        "‚ö†Ô∏è **Required for dataset download**\n",
        "\n",
        "1. Go to your [Roboflow Settings](https://app.roboflow.com/settings/api)\n",
        "2. Copy your private API key\n",
        "3. In Colab, click the **key icon** (üîë) on the **left sidebar** to open Secrets\n",
        "4. Click `+ Add Secret`\n",
        "5. Add a new secret:\n",
        "   - **Name**: `ROBOFLOW_API_KEY` (exact name, case-sensitive)\n",
        "   - **Value**: Paste your API key\n",
        "6. **Enable access**: Toggle the switch next to `ROBOFLOW_API_KEY` to **ON** (this grants the notebook access to the secret)\n",
        "\n",
        "---\n",
        "\n",
        "### Step 3: Configure Roboflow Project Information\n",
        "\n",
        "‚ö†Ô∏è **Required for dataset download**\n",
        "\n",
        "1. In Roboflow, navigate to your project ‚Üí `Versions` ‚Üí `Train` ‚Üí `Download Dataset`\n",
        "2. Under `Image and Annotation Format`, select **`COCO`**\n",
        "3. Click `Show download code` ‚Üí `Continue`\n",
        "4. Select **`Jupyter`** as the format\n",
        "5. **Copy the 3rd line** that looks like:\n",
        "   ```\n",
        "   project = rf.workspace(\"your-workspace\").project(\"your-project\")\n",
        "   ```\n",
        "6. In the Colab notebook, find the code block marked:\n",
        "   ```\n",
        "   ‚ö†Ô∏è PASTE YOUR PROJECT CODE LINE IN THE CODE BLOCK BELOW\n",
        "   ```\n",
        "7. **Paste** the copied line into that code block\n",
        "8. **Adjust the version number** in the line below if needed (default = 1)\n",
        "\n",
        "---\n",
        "\n",
        "### Step 4: Adjust Number of Classes\n",
        "\n",
        "‚ö†Ô∏è **IMPORTANT: Update class count if your dataset has a different number of classes**\n",
        "\n",
        "- **Default**: 4 classes\n",
        "- **Action**: Search for all occurrences of `num_classes` or class count settings in the notebook and update them to match your dataset\n",
        "\n",
        "**Example**: If your dataset has 5 classes, change `num_classes=4` to `num_classes=5` in all relevant code blocks.\n",
        "\n",
        "---\n",
        "\n",
        "## Ready to Run\n",
        "\n",
        "After completing all setup steps above, you can run the notebook cells in order. The notebook will:\n",
        "1. Download your dataset from Roboflow\n",
        "2. Train the Swift-YOLO model\n",
        "3. Export the model as `int8_vela.tflite` for Grove Vision AI V2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check PGU and Python version"
      ],
      "metadata": {
        "id": "jSvMrw5uQfli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "!nvidia-smi\n",
        "\n",
        "# Check Python version\n",
        "!python --version"
      ],
      "metadata": {
        "id": "gKht7yXrNzKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlf8_bNg2xWK"
      },
      "source": [
        "## Prerequisites\n",
        "### Setup SSCMA\n",
        "Clone the [repository](https://github.com/Seeed-Studio/ModelAssistant) and install the dependencies.\n",
        "\n",
        "(you can ignore the ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v97_kWgU2xWK"
      },
      "outputs": [],
      "source": [
        "!pip install ethos-u-vela\n",
        "!git clone https://github.com/Seeed-Studio/ModelAssistant.git -b 2.0.0  #clone the repo\n",
        "%cd ModelAssistant\n",
        "!. ./scripts/setup_colab.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mKfjj3T2xWL"
      },
      "source": [
        "### Download the pretrain model weights file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SewV9Zvp2xWL"
      },
      "outputs": [],
      "source": [
        "%mkdir -p Swift-YOLO_192\n",
        "!wget -c https://files.seeedstudio.com/sscma/model_zoo/detection/gesture/swift_yolo_1xb16_300e_coco_sha1_adda465db843aae8384c90c82e223c2cd931cad2.pth -O Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT5ctFj-2xWL"
      },
      "source": [
        "### Download the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download original model from Seeed"
      ],
      "metadata": {
        "id": "c-0mShbZGC6j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "V6Hespbd2xWL"
      },
      "outputs": [],
      "source": [
        "%mkdir -p Swift-YOLO_192\n",
        "!pip install roboflow\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"ROBOFLOW_API_KEY\"] = userdata.get(\"ROBOFLOW_API_KEY\")\n",
        "from roboflow import download_dataset\n",
        "dataset = download_dataset(\"https://universe.roboflow.com/rsp/paper-aaj0p/dataset/33\", \"coco\")\n",
        "dataset_path = dataset.location\n",
        "import shutil\n",
        "shutil.move(dataset_path, \"Swift-YOLO_192/dataset\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ö†Ô∏è PASTE YOUR PROJECT CODE LINE IN THE CODE BLOCK BELOW"
      ],
      "metadata": {
        "id": "riErVi3uGMVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir -p Swift-YOLO_192\n",
        "!pip install roboflow\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import userdata\n",
        "from roboflow import Roboflow\n",
        "\n",
        "# Setup API Key from Colab Secrets.\n",
        "# Make sure you add you Roboflow API key to the secrets (under key symbol, left side bar in colab)\n",
        "api_key = userdata.get(\"ROBOFLOW_API_KEY\")\n",
        "rf = Roboflow(api_key=api_key)\n",
        "\n",
        "# PASTE YOUR PROJECT CODE LINE HERE:\n",
        "project = rf.workspace(\"pcv-eagdp\").project(\"vvel\")\n",
        "version = project.version(1)\n",
        "\n",
        "dataset = version.download(\"coco\")\n",
        "dataset_path = dataset.location\n",
        "dest_path = \"Swift-YOLO_192/dataset\"\n",
        "if os.path.exists(dest_path):\n",
        "    shutil.rmtree(dest_path) # Remove existing to prevent nested folders\n",
        "\n",
        "shutil.move(dataset_path, dest_path)\n",
        "\n",
        "print(f\"Dataset successfully moved to: {dest_path}\")"
      ],
      "metadata": {
        "id": "Vuhw1EfJFaHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5XfzBgq2xWL"
      },
      "source": [
        "## Train a model with SSCMA\n",
        "All the training parameters are in the `config.py` file, you can change the parameters to train your own model.\n",
        "\n",
        "Below are explanations of some common parameters. You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/config) for more details.\n",
        "- `data_root` - the datasets path.\n",
        "- `epochs`- the train epochs. **we use 10 epochs as an example**.\n",
        "- `batch_size` - the batch size.\n",
        "- `height` - the image height.\n",
        "- `width` - the image width.\n",
        "- `load_from` - the pretrained model path.\n",
        "- `num_classes` - the number of classes.\n",
        "\n",
        "You can overwrite the parameters in the `config.py` file by using the `--cfg-options` argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qPELuZQ2xWL"
      },
      "outputs": [],
      "source": [
        "!sscma.train configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Swift-YOLO_192 \\\n",
        "    num_classes=4 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXrO8voV2xWL"
      },
      "source": [
        "## Export the model\n",
        "After training, you can export the model to the format for deployment. SSCMA supports exporting to ONNX, and TensorFlow Lite at present.\n",
        "You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/export/overview) for more details.\n",
        "\n",
        "```bash\n",
        "python3 tools/export.py \\\n",
        "    \"<CONFIG_FILE_PATH>\" \\\n",
        "    \"<CHECKPOINT_FILE_PATH>\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjoiLAts2xWL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "with open('Swift-YOLO_192/last_checkpoint', 'r') as f:\n",
        "\tos.environ['CHECKPOINT_FILE_PATH'] = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogpkuqhT2xWL"
      },
      "outputs": [],
      "source": [
        "!sscma.export configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py $CHECKPOINT_FILE_PATH --cfg-options  \\\n",
        "    work_dir=Swift-YOLO_192 \\\n",
        "    num_classes=4 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgCw6sy82xWM"
      },
      "source": [
        "### Evaluate the model\n",
        "After exporting the model, you can evaluate the model on the test dataset.\n",
        "You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/export/overview) for more details.\n",
        "\n",
        "\n",
        "```bash\n",
        "python3 tools/inference.py \\\n",
        "    \"<CONFIG_FILE_PATH>\" \\\n",
        "    \"<CHECKPOINT_FILE_PATH>\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv6LhFks2xWM"
      },
      "source": [
        "### Evaluate the PyTorch model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXi-29wD2xWM"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}.pth \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Swift-YOLO_192 \\\n",
        "    num_classes=4 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAc0Bm3n2xWM"
      },
      "source": [
        "### Evaluate the ONNX model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLSAumn-2xWM"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.onnx \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Swift-YOLO_192 \\\n",
        "    num_classes=7 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5i1EdzS2xWM"
      },
      "source": [
        "### Evaluate the TFLite FLOAT32 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFHGINFj2xWM"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.tflite \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Swift-YOLO_192 \\\n",
        "    num_classes=7 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5PdnXK82xWM"
      },
      "source": [
        "### Evaluate the TFLite INT8 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZy0HhuN2xWM"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_int8.tflite \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Swift-YOLO_192 \\\n",
        "    num_classes=4 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfGi1i-d2xWM"
      },
      "source": [
        "## Deploy the model\n",
        "After model training, evaluation and export, you can deploy the model to your device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UitVGQJi2xWM"
      },
      "outputs": [],
      "source": [
        "%ls -lh Swift-YOLO_192/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zip and download the Swift-YOLO_192 model"
      ],
      "metadata": {
        "id": "L-umWJwvW_bX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "\n",
        "# Define the paths\n",
        "folder_path = '/content/ModelAssistant/Swift-YOLO_192'\n",
        "zip_filename = 'Swift-YOLO_Models.zip'\n",
        "\n",
        "# Create the zip file\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    # List all items in the directory\n",
        "    for item in os.listdir(folder_path):\n",
        "        item_path = os.path.join(folder_path, item)\n",
        "\n",
        "        # Only add to zip if it's a file (skips all subdirectories)\n",
        "        if os.path.isfile(item_path):\n",
        "            zipf.write(item_path, arcname=item)\n",
        "            print(f\"Added to zip: {item}\")\n",
        "\n",
        "# Automatically trigger the download to your computer\n",
        "files.download(zip_filename)"
      ],
      "metadata": {
        "id": "v4SvKLwcWw0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy model on [SenseCraft AI platform](https://sensecraft.seeed.cc/ai/model)\n",
        "\n",
        "1. Click `My Own Models`\n",
        "2. Select `+ Add Model`\n",
        "3. Follow the instructions\n",
        "4. Download the int8_vela.tflite model"
      ],
      "metadata": {
        "id": "QjNdDA3Cb6iz"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "collapsed_sections": [
        "NAc0Bm3n2xWM",
        "e5i1EdzS2xWM"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}